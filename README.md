# LAD_test
### Тестовые задания

### Задание 1.
Написать алгоритм парсинга данных по вакансиям для IT-специалистов с одного из ресурсов: hh.ru, career.habr.com/vacancies и т.д.

Алгоритм позволяет получить информацию о количестве вакансий по направлениям Аналитика данных и Data Science в разрезе уровней (Junior, Middle, Senior). 

За основу можно взять как один регион (НН, Москва и т.д.)  так и несколько.

### [Результат:](https://github.com/danilabdullin/LAD_test/tree/main/Parser)


Работа выполнена с применением фреймворка Scrapy и системы управления базами данных MongoDB. Scrapy существенно способствовал предотвращению блокировок при парсинге данных благодаря гибкой настройке параметров, включая скорость парсинга, задаваемую в едином конфигурационном файле.

Полученные данные были сохранены в MongoDB и экспортированы в формат JSON для дальнейшего использования. Этот подход позволил собирать всю доступную информацию о вакансиях, включая дополнительные детали, указанные в описаниях. Для анализа наличия вакансий в категориях "junior", "middle" и "senior" использовалась информация о требуемом опыте, так как не всегда грейд указан непосредственно в названии вакансии.

Дополнительный анализ данных может быть проведен с использованием библиотек Python, а также средств, предоставляемых MongoDB. Например, можно легко выбрать все вакансии, требующие более 3 лет опыта, что показано на соответствующем скриншоте. В Москве доступно 131 такая вакансия.


<img width="1064" alt="Mongo" src="https://github.com/danilabdullin/LAD_test/assets/66716757/c44a8306-0811-432f-933f-84b8667ff545">


### Задание 2. 
Написать алгоритм распознавания и поиска текста из pdf файла.

Пример файла https://www.archive-nnov.ru/?id=24998 (печатный документ), https://www.archive-nnov.ru/?id=37046 (рукописный документ).
Пример реализации: https://www.genotek.ru/archives/ 

### [Результат:](https://github.com/danilabdullin/LAD_test/tree/main/OCR)

Для разработки решения, направленного на поиск и распознавание текста в печатных архивах, была использована библиотека Tesseract-OCR в качестве основного инструмента. Однако, при работе с рукописным текстом, была задействована глубокая нейронная сеть, объединяющая в себе ResNet-50 и технологию Transformer.

Результаты работы данной нейросети, примененной к рукописному тексту, извлеченному из образца, представлены на следующих скриншотах. Для успешной обработки полного PDF-файла необходима разработка нейросети, способной точно обнаруживать рукописный текст на архивных документах. Попытка применения предобученной нейронной сети для детекции рукописного текста оказалась неудачной.


<img width="385" alt="hand1" src="https://github.com/danilabdullin/LAD_test/assets/66716757/9b541e4e-a638-4161-adf4-1cbfb9b011ff">

<img width="398" alt="hand2" src="https://github.com/danilabdullin/LAD_test/assets/66716757/e0a139aa-4d12-4c59-8af4-256f289f7d7d">
